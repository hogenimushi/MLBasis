{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chainer チュートリアル その１\n",
    "\n",
    "https://qiita.com/mitmul/items/eccf4e0a84cb784ba84a\n",
    "のなかから、学習の基本的な部分を実行してみる。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNISTの準備\n",
    "\n",
    "\n",
    "研究をするためには、本当は自分でデータを読み書きしたほうが良い。\n",
    "自分で作ったニューラルネットのデバイスにデータを投入して、データをとるためである。\n",
    "今回はChainarに集中するために、\n",
    "ChanerにはMNISTを呼び出してくれる便利な関数があるので、それを使う。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4QeCIvxAUIQfCIrwA0H9H4BpmwJXvvG+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f33c40c90b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 5\n"
     ]
    }
   ],
   "source": [
    "from chainer.datasets import mnist\n",
    "\n",
    "# データがダウンロードされていなければ、ダウンロードを行う\n",
    "train, test = mnist.get_mnist(withlabel=True, ndim=1)\n",
    "\n",
    "# matplotlibがnotebookに反映されるようにする。\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# データを例示する\n",
    "x, t = train[0]\n",
    "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "print('label:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trainとtestの配列の大きさを見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(train))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Iteratorを作る "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットから一部のデータを取得し、それらを束ねてミニバッチを作成して学習を行おう。\n",
    "学習はデータの投入、forwardの計算、重みの更新、の繰り返しで行うが、このループを抽象化したのがIteratorである。\n",
    "Cainarではミニバッチに対して行う、学習やテストなどの繰り返しをIteratorをというオブジェクトで取り扱う。\n",
    "この後の学習ループはIteratorを使用していく。\n",
    "\n",
    "イテレータは、next()メソッドで新しいミニバッチを返す。内部ではデータセットを何周走査したか（epoch）、\n",
    "現在のイテレーションが新しいepochの最初のイテレーションかどうかを管理するプロパティ（is_new_epoch）、\n",
    "など、実験に必要な情報を保持する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import iterators\n",
    "\n",
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "test_iter = iterators.SerialIterator(test, batchsize,\n",
    "                                     repeat=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iteratorについて\n",
    "\n",
    "Iterate:反復する\n",
    "\n",
    "\n",
    "Iteratorは、配列に入っているデータの読み出しの管理をするオブジェクトである。\n",
    "\n",
    "Chainerが用意しているSerialIteratorは、\n",
    "データセットの中のデータを順番に取り出してくる最もシンプルなIteratorである。\n",
    "データセットオブジェクトと、バッチサイズ指定すると、\n",
    "データオブジェクトからランダムでバッチサイズの数だけデータを取り出し、\n",
    "繰り返し読み出す準備をする。\n",
    "\n",
    "渡したデータセットオブジェクトから、データを繰り返し読み出す必要がある場合はrepeat引数をTrueとし、\n",
    "一巡したらそれ以上データを取り出したくない場合はこれをFalseとする。\n",
    "デフォルトでは、True。\n",
    "\n",
    "shuffle引数にTrueを渡すと、データセットから取り出されてくるデータの順番をエポックごとにランダムに変更する。\n",
    "\n",
    "batchsize = 128としているので、train_iterとtest_iterは、それぞれ128枚の数字画像データを読み出すためのIteratorということになる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. モデルの定義\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、三層パーセプトロンを定義する。\n",
    "\n",
    "ここで用いるMNISTデータセットは10種のラベルを持つため10とし、\n",
    "中間層のユニット数は100とする。\n",
    "\n",
    "Chainarでは、Link, Function, Chain、オブジェクトを用いて、ニューラルネットのモデルを記述していく。\n",
    "\n",
    "\n",
    "## LinkとFunction\n",
    " \n",
    "Linkとfunctionは、ニューラルネットの層を記述するためのオブジェクトである。\n",
    "\n",
    "|          |Link           |Function         |\n",
    "|----------|---------------|-----------------|\n",
    "|パラメータ|持たない       |持つ             |\n",
    "|モジュール| chainer.links |chainer.functions|\n",
    "\n",
    "慣習的に以下のようにimportしておく.\n",
    "\n",
    "`\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "`\n",
    "\n",
    "`L.Convolution2D()`や`F.relu()` などとして使う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain\n",
    "\n",
    "Chainは、Linkを集めて、パラメータを持つ層を表現するクラスである。\n",
    "学習の時には、Chainに入っているパラメータを更新していく。\n",
    "Chainerで学習を行うときは、学習中にOptimizerが更新すべき全てのパラメータを簡単に取得できるように、Chainで一箇所にまとめておく。\n",
    "\n",
    "また、モデルはChainクラスを継承したクラスとして定義されることが多い。\n",
    "モデルを表すクラスのコンストラクタで、親クラスのコンストラクタにキーワード引数の形で登録したい層の名前と、オブジェクトを渡しておくと、自動的にOptimizerから見つけられる形で保持される。また、別の場所でadd_linkメソッドを使っても行うことができる。\n",
    "\n",
    "関数呼び出しのようにしてモデルに()アクセサでデータを渡せるように、__call__メソッドを定義して、その中にforward処理を記述すると便利である。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの定義\n",
    "実際のモデルの定義を示す。\n",
    "\n",
    "1. ChainのサブクラスとしてMLPを定義している\n",
    "2. 親クラスのコンストラクタに、層の名前を渡し、パラメータを持つオブジェクトを定義している。\n",
    "3. `__call__`メソッドで、データを受け取ったときの計算を決めている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "\n",
    "class MLP(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_mid_units=100, n_out=10):\n",
    "        # パラメータを持つ層の登録\n",
    "        super(MLP, self).__init__(\n",
    "            l1=L.Linear(None, n_mid_units),\n",
    "            l2=L.Linear(n_mid_units, n_mid_units),\n",
    "            l3=L.Linear(n_mid_units, n_out),\n",
    "        )\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # データを受け取った際のforward計算を書く\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)\n",
    "\n",
    "model = MLP()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`L.Linear`は全結合層であり、引数は入力の数と出力の数である。これらが入力されると、パラメータが$入力\\times 出力$だけ自動的に確保される。\n",
    "\n",
    "`F.relu`はrelu関数で出力を評価し、出力値を変換する、という意味である。ステップ関数やシグモイド関数も用意されている。\n",
    "\n",
    "'Linear'クラスは、Wとbのメンバ変数を持つ。Wはパラメータ行列、bはバイアスである。バイアスを見てみよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1つ目の全結合相のバイアスパラメータの形は、 (100,)\n",
      "初期化直後のその値は、 [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print('1つ目の全結合相のバイアスパラメータの形は、', model.l1.b.shape)\n",
    "print('初期化直後のその値は、', model.l1.b.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variable W([[-0.04102618  0.02721617 -0.12853308 ...,  0.08807396\n",
      "             -0.08484822 -0.01528504]\n",
      "            [-0.10545832  0.04503953 -0.14108773 ..., -0.06105508\n",
      "              0.10733379  0.22184092]\n",
      "            [ 0.03949065  0.00160416  0.10991538 ...,  0.02825215\n",
      "             -0.01454245  0.0142852 ]\n",
      "            ..., \n",
      "            [-0.0999627   0.07811061 -0.04531647 ...,  0.24858736\n",
      "             -0.0011903  -0.0678406 ]\n",
      "            [-0.03981388  0.01258735 -0.12455377 ...,  0.12476893\n",
      "              0.0600693   0.20158371]\n",
      "            [ 0.02554563  0.0544226   0.09823129 ...,  0.04297119\n",
      "              0.09561111  0.01461734]])\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "print(model.l2.W)\n",
    "print(model.l2.W.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習のステップは以下のようになる。\n",
    "\n",
    "1. 予測値の計算\n",
    "1. 損失関数の計算\n",
    "1. 重みの更新\n",
    "1. 適切なところで途中結果を表示\n",
    "\n",
    "まず、現在の重みでMLPに分類を行わせる。\n",
    "その結果は、入力された画像がどのクラスに分類されるか？という\n",
    "10個のニューロンからの出力である。\n",
    "\n",
    "次に、損失関数の計算を行う。得られた出力が合っているか誤っているかを\n",
    "判断する値を実数で算出する。\n",
    "\n",
    "最後に、重みを更新する。得られた出力が誤っている場合、重みを正しい方向に\n",
    "修正する必要がある。重みを修正するアルゴリズムは最適化手法といい、\n",
    "chainer.optimizersモジュール以下から選択できる。\n",
    "\n",
    "ここでは、最適化手法として勾配降下法の手法であるoptimizers.SGDを用いる。\n",
    "Optimizerのオブジェクトには、setupメソッドを使ってChainオブジェクトを渡す。\n",
    "こうすることでOptimizerは、自身が更新すべきモデル内のパラメータを自動的に検出する。\n",
    "\n",
    "最適化手法は他に、MomentumSGD, RMSprop, Adamがある。`chainer.optimizers.SGD`の部分を`chainer.optimizers.最適化手法名`と変更することで手軽に試せるので、色々と試してみて結果の変化を見てみるとよい。\n",
    "\n",
    "from chainer import optimizers\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "optimizer.setup(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import optimizers\n",
    "optimizer = optimizers.SGD(lr=0.01)\n",
    "optimizer.setup(model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:01 train_loss:0.7337 val_loss:0.7289 val_accuracy:0.8339\n",
      "epoch:02 train_loss:0.4378 val_loss:0.4538 val_accuracy:0.8803\n",
      "epoch:03 train_loss:0.2786 val_loss:0.3752 val_accuracy:0.8973\n",
      "epoch:04 train_loss:0.3122 val_loss:0.3368 val_accuracy:0.9053\n",
      "epoch:05 train_loss:0.3565 val_loss:0.3117 val_accuracy:0.9108\n",
      "epoch:06 train_loss:0.3596 val_loss:0.2959 val_accuracy:0.9160\n",
      "epoch:07 train_loss:0.2818 val_loss:0.2817 val_accuracy:0.9198\n",
      "epoch:08 train_loss:0.2877 val_loss:0.2713 val_accuracy:0.9237\n",
      "epoch:09 train_loss:0.3340 val_loss:0.2609 val_accuracy:0.9254\n",
      "epoch:10 train_loss:0.2545 val_loss:0.2516 val_accuracy:0.9291\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from chainer.dataset import concat_examples\n",
    "\n",
    "max_epoch = 10\n",
    "\n",
    "while train_iter.epoch < max_epoch:\n",
    "\n",
    "    # ---------- 学習の1イテレーション ----------\n",
    "    train_batch = train_iter.next()\n",
    "    x, t = concat_examples(train_batch, -1)\n",
    "\n",
    "    # 予測値の計算\n",
    "    y = model(x)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    # 勾配の計算\n",
    "    model.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    # パラメータの更新\n",
    "    optimizer.update()\n",
    "    # --------------- ここまで ----------------\n",
    "\n",
    "    # 1エポック終了ごとにValidationデータに対する予測精度を測って、\n",
    "    # モデルの汎化性能が向上していることをチェックしよう\n",
    "    if train_iter.is_new_epoch:  # 1 epochが終わったら\n",
    "\n",
    "        # ロスの表示\n",
    "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
    "            train_iter.epoch, float(loss.data)), end='')\n",
    "\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        while True:\n",
    "            test_batch = test_iter.next()\n",
    "            x_test, t_test = concat_examples(test_batch, -1)\n",
    "\n",
    "            # テストデータをforward\n",
    "            y_test = model(x_test)\n",
    "\n",
    "            # ロスを計算\n",
    "            loss_test = F.softmax_cross_entropy(y_test, t_test)\n",
    "            test_losses.append(loss_test.data)\n",
    "\n",
    "            # 精度を計算\n",
    "            accuracy = F.accuracy(y_test, t_test)\n",
    "            accuracy.to_cpu()\n",
    "            test_accuracies.append(accuracy.data)\n",
    "\n",
    "            if test_iter.is_new_epoch:\n",
    "                test_iter.epoch = 0\n",
    "                test_iter.current_position = 0\n",
    "                test_iter.is_new_epoch = False\n",
    "                test_iter._pushed_position = None\n",
    "                break\n",
    "\n",
    "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
    "            np.mean(test_losses), np.mean(test_accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "val_accuracyをみると、0.93近くの値になっている。シンプルな3層ネットワークでも、93%の認識率が出ているようだ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 学習したモデルを使う"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習を行ったら、そのモデルを保存しておき、実際に分類を行うときに\n",
    "保存したモデルを読み込んで使用する。\n",
    "\n",
    "## モデルの保存\n",
    "モデルを保存するための形式はHDF5とNumpyのNPZが選べる。HDF5形式のほうが汎用性があるが、今回は簡単のため追加ライブラリの不要なNPZで保存しよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 aslguest aslguest 333915 10月  3 11:37 my_mnist.model\r\n"
     ]
    }
   ],
   "source": [
    "from chainer import serializers\n",
    "\n",
    "serializers.save_npz('my_mnist.model', model)\n",
    "\n",
    "# ちゃんと保存されていることを確認\n",
    "%ls -la my_mnist.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの読み込みと使用\n",
    "\n",
    "上で保存したNPZファイルを読み込んで、テストデータに対するラベルの予測を行ってみる。\n",
    "保存したNPZファイルにはMLPモデルのパラメータが記録されているので、\n",
    "まずはモデルのオブジェクトを生成し、そのなかにNPZが持っている値を書き込むことで、\n",
    "読み出しを実現する。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH0iK8ANJEX4gKcIPJEX4gaQIP5DUXwFGhz+pWT5yuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f337940dfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: 7\n"
     ]
    }
   ],
   "source": [
    "# まず同じモデルのオブジェクトを作る\n",
    "infer_model = MLP()\n",
    "\n",
    "# そのオブジェクトに保存済みパラメータをロードする\n",
    "serializers.load_npz('my_mnist.model', infer_model)\n",
    "\n",
    "# テストデータ\n",
    "x, t = test[0]\n",
    "plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "plt.show()\n",
    "print('label:', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これで、学習->保存->推論ができた。\n",
    "時間のかかる学習も一度やっておけば、モデルの保存と読み出しを行うことで、推論をすることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPUの利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習時間を短縮するために、GPUを利用しよう。\n",
    "\n",
    "GPUはPCとPCI Expressインターフェイスで接続されていて、CPUとは異なるメモリをつかう。\n",
    "GPUに計算をさせるためには、CPUとGPUのデータのやりとりを少し書かなければならない。\n",
    "\n",
    "モデルはChainのサブクラスで定義したクラスであった。この、モデルをGPUで実行させるために、インスタンスに`to_gpu()`メソッドで\n",
    "GPUで実行させるための指示をする。GPUは0から始まるidで管理されている。`to_gpu()`メソッドを呼び出すときに、GPUのIDを渡す。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MLP at 0x7f337941b080>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_id=0\n",
    "gpu_model = MLP()\n",
    "gpu_model.to_gpu(gpu_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、乱数の生成系列の固定を行う。この操作は必須ではないが、実行するたびに異なる結果が出力されることを防ぐ効果があり、実験をする場合には便利である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "numpy.random.seed(0)\n",
    "import chainer\n",
    "if chainer.cuda.available:\n",
    "    chainer.cuda.cupy.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次に、optimizerの設定と、訓練ループを示す。optimizerの設定は変更がないが、訓練ループでは、結果の表示にGPUからCPUへデータを転送するための関数`to_cpu()`を使っていることに気をつけること。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:01 train_loss:0.7327 val_loss:0.7453 val_accuracy:0.8357\n",
      "epoch:02 train_loss:0.3664 val_loss:0.4452 val_accuracy:0.8822\n",
      "epoch:03 train_loss:0.4008 val_loss:0.3721 val_accuracy:0.8985\n",
      "epoch:04 train_loss:0.3041 val_loss:0.3315 val_accuracy:0.9090\n",
      "epoch:05 train_loss:0.2769 val_loss:0.3088 val_accuracy:0.9124\n",
      "epoch:06 train_loss:0.2982 val_loss:0.2934 val_accuracy:0.9157\n",
      "epoch:07 train_loss:0.2013 val_loss:0.2802 val_accuracy:0.9190\n",
      "epoch:08 train_loss:0.2289 val_loss:0.2682 val_accuracy:0.9226\n",
      "epoch:09 train_loss:0.3878 val_loss:0.2589 val_accuracy:0.9243\n",
      "epoch:10 train_loss:0.2515 val_loss:0.2497 val_accuracy:0.9269\n"
     ]
    }
   ],
   "source": [
    "from chainer.cuda import to_cpu\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "\n",
    "batchsize = 128\n",
    "\n",
    "train_iter = iterators.SerialIterator(train, batchsize)\n",
    "test_iter = iterators.SerialIterator(test, batchsize,\n",
    "                                     repeat=False, shuffle=False)\n",
    "\n",
    "gpu_opt = optimizers.SGD(lr=0.01)\n",
    "gpu_opt.setup(gpu_model)\n",
    "\n",
    "max_epoch = 10\n",
    "\n",
    "while train_iter.epoch < max_epoch:\n",
    "\n",
    "    # ---------- 学習の1イテレーション ----------\n",
    "    train_batch = train_iter.next()\n",
    "    x, t = concat_examples(train_batch, gpu_id)  # GPUに訓練データを転送する\n",
    "\n",
    "    # 予測値の計算\n",
    "    y = gpu_model(x)\n",
    "\n",
    "    # ロスの計算\n",
    "    loss = F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    \n",
    "    # 勾配の計算\n",
    "    gpu_model.cleargrads()\n",
    "    loss.backward()\n",
    "\n",
    "    # パラメータの更新\n",
    "    gpu_opt.update()\n",
    "    # --------------- ここまで ----------------\n",
    "\n",
    "    # 1エポック終了ごとにValidationデータに対する予測精度を測って、\n",
    "    # モデルの汎化性能が向上していることをチェックしよう\n",
    "    if train_iter.is_new_epoch:  # 1 epochが終わったら\n",
    "\n",
    "        # ロスの表示\n",
    "        print('epoch:{:02d} train_loss:{:.04f} '.format(\n",
    "            train_iter.epoch, float(to_cpu(loss.data))), end='') # loss.dataはGPUからCPUへ転送されている\n",
    "\n",
    "        test_losses = []\n",
    "        test_accuracies = []\n",
    "        while True:\n",
    "            test_batch = test_iter.next()\n",
    "            x_test, t_test = concat_examples(test_batch, gpu_id) #テストデータをGPUに転送する\n",
    "\n",
    "            # テストデータをforward\n",
    "            y_test = gpu_model(x_test)\n",
    "\n",
    "            # ロスを計算\n",
    "            loss_test = F.softmax_cross_entropy(y_test, t_test)\n",
    "            test_losses.append(to_cpu(loss_test.data)) # loss.dataはGPUからCPUへ転送されている\n",
    "\n",
    "            # 精度を計算\n",
    "            accuracy = F.accuracy(y_test, t_test)\n",
    "            accuracy.to_cpu() # accuracyはGPUからCPUに転送されている\n",
    "            test_accuracies.append(accuracy.data)\n",
    "\n",
    "            if test_iter.is_new_epoch:\n",
    "                test_iter.epoch = 0\n",
    "                test_iter.current_position = 0\n",
    "                test_iter.is_new_epoch = False\n",
    "                test_iter._pushed_position = None\n",
    "                break\n",
    "\n",
    "        print('val_loss:{:.04f} val_accuracy:{:.04f}'.format(\n",
    "            np.mean(test_losses), np.mean(test_accuracies))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "GPUでの実行を最適化していないので速度向上は少なかったが、結果を得ることができた。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# まとめ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここではChainarの練習として、MNISTデータを読み込んで、3層のニューラルネットで学習を行った。\n",
    "また、学習したパラメータ（重み）の保存と読み込み、GPU上での実行も行った。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
